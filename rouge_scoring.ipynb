{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c69bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from itertools import combinations\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcf302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(data_path):\n",
    "    data = []\n",
    "    with open(data_path) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c73e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_jsonl(\"reddit_data/reddit_cands_100.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "655e7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d10302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in data:\n",
    "    cands = list(combinations(entry['idx'], 2))\n",
    "    cands += list(combinations(entry['idx'], 3))\n",
    "    cands = [' '.join(tup) for tup in cands]\n",
    "    scores = []\n",
    "    for cand in cands:\n",
    "        rouge_scores = scorer.score(cand, entry['summary'])\n",
    "        score = sum([s.fmeasure for s in rouge_scores.values()]) / 3\n",
    "        scores.append((cand, score))\n",
    "    scores.sort(key=lambda x : x[1], reverse=True)\n",
    "    entry['scores'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fca4da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06276974",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = df_temp.text.str.len().max()\n",
    "def pad_text(text):\n",
    "    curr = word_tokenize(text)\n",
    "    curr.extend([0]*(max_len-len(curr)))\n",
    "    return curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "710b7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['text'] = df_temp['text'].apply(pad_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f09348",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = df_temp.summary.str.len().max()\n",
    "def pad_sum(text):\n",
    "    curr = word_tokenize(text)\n",
    "    curr.extend([0]*(max_len-len(curr)))\n",
    "    return curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccb876c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['summary'] = df_temp['summary'].apply(pad_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d61dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([max([len(s) for s in lst]) for lst in df_temp['idx']]) * 3\n",
    "def pad_scores(lst):\n",
    "    result = []\n",
    "    for tup in lst:\n",
    "        temp = word_tokenize(tup[0])\n",
    "        temp.extend([0]*(max_len-len(temp)))\n",
    "        result.append((temp, tup[1]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea0d1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['scores'] = df_temp['scores'].apply(pad_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af2fcdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>idx</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[this, actually, happened, a, couple, of, year...</td>\n",
       "      <td>[confuse, a, 5th, grade, girl, for, a, boy, in...</td>\n",
       "      <td>[i grew up in germany where i went to a german...</td>\n",
       "      <td>[([i, grew, up, in, germany, where, i, went, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[it, was, last, october, ,, but, i, 'm, feelin...</td>\n",
       "      <td>[i, found, my, estranged, dad, ,, thought, i, ...</td>\n",
       "      <td>[it was last october, but i'm feeling the fall...</td>\n",
       "      <td>[([during, the, most, acute, months, of, griev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[so, i, had, the, brilliant, idea, to, use, ve...</td>\n",
       "      <td>[had, my, balls, burned, by, sauron, and, was,...</td>\n",
       "      <td>[so i had the brilliant idea to use veet hair ...</td>\n",
       "      <td>[([the, slight, peroxide, kinda, smell, ensued...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[today, i, was, going, to, have, a, bath, afte...</td>\n",
       "      <td>[peppermint, +, bath, =, burning, cold, ladybi...</td>\n",
       "      <td>[today i was going to have a bath after a long...</td>\n",
       "      <td>[([today, i, was, going, to, have, a, bath, af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, have, n't, had, a, bath, in, practically, ...</td>\n",
       "      <td>[got, too, high, and, too, hot, in, the, bath,...</td>\n",
       "      <td>[i haven't had a bath in practically years so,...</td>\n",
       "      <td>[([picture, this, ;, a, very, cramped, bathroo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[a, bit, of, background, :, i, 'm, almost, cer...</td>\n",
       "      <td>[pooped, and, peed, all, over, a, porta-potty,...</td>\n",
       "      <td>[a bit of background: i'm almost certain that ...</td>\n",
       "      <td>[([as, i, begin, ,, as, my, friend, once, put,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[average, day, at, work, ,, not, too, busy, ,,...</td>\n",
       "      <td>[turn, around, for, a, split, second, ,, littl...</td>\n",
       "      <td>[average day at work, not too busy, not too sl...</td>\n",
       "      <td>[([i, 'm, getting, ready, to, go, on, my, brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[so, my, day, pretty, much, sucked, ., let, 's...</td>\n",
       "      <td>[i, ate, a, wendy, 's, frosty, ,, got, the, sh...</td>\n",
       "      <td>[let's start off with the shitty morning of me...</td>\n",
       "      <td>[([we, drove, to, wendy, 's, and, ordered, fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[yesterday, evening, my, mother, and, i, were,...</td>\n",
       "      <td>[did, n't, sit, down, while, taking, off, my, ...</td>\n",
       "      <td>[yesterday evening my mother and i were walkin...</td>\n",
       "      <td>[([for, some, odd, reason, ,, i, did, n't, sit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[using, a, throwaway, because, well, ,, who, k...</td>\n",
       "      <td>[i, may, have, incidentally, met, dwayne, john...</td>\n",
       "      <td>[using a throwaway because well, who knows who...</td>\n",
       "      <td>[([using, a, throwaway, because, well, ,, who,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   [this, actually, happened, a, couple, of, year...   \n",
       "1   [it, was, last, october, ,, but, i, 'm, feelin...   \n",
       "2   [so, i, had, the, brilliant, idea, to, use, ve...   \n",
       "3   [today, i, was, going, to, have, a, bath, afte...   \n",
       "4   [i, have, n't, had, a, bath, in, practically, ...   \n",
       "..                                                ...   \n",
       "95  [a, bit, of, background, :, i, 'm, almost, cer...   \n",
       "96  [average, day, at, work, ,, not, too, busy, ,,...   \n",
       "97  [so, my, day, pretty, much, sucked, ., let, 's...   \n",
       "98  [yesterday, evening, my, mother, and, i, were,...   \n",
       "99  [using, a, throwaway, because, well, ,, who, k...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   [confuse, a, 5th, grade, girl, for, a, boy, in...   \n",
       "1   [i, found, my, estranged, dad, ,, thought, i, ...   \n",
       "2   [had, my, balls, burned, by, sauron, and, was,...   \n",
       "3   [peppermint, +, bath, =, burning, cold, ladybi...   \n",
       "4   [got, too, high, and, too, hot, in, the, bath,...   \n",
       "..                                                ...   \n",
       "95  [pooped, and, peed, all, over, a, porta-potty,...   \n",
       "96  [turn, around, for, a, split, second, ,, littl...   \n",
       "97  [i, ate, a, wendy, 's, frosty, ,, got, the, sh...   \n",
       "98  [did, n't, sit, down, while, taking, off, my, ...   \n",
       "99  [i, may, have, incidentally, met, dwayne, john...   \n",
       "\n",
       "                                                  idx  \\\n",
       "0   [i grew up in germany where i went to a german...   \n",
       "1   [it was last october, but i'm feeling the fall...   \n",
       "2   [so i had the brilliant idea to use veet hair ...   \n",
       "3   [today i was going to have a bath after a long...   \n",
       "4   [i haven't had a bath in practically years so,...   \n",
       "..                                                ...   \n",
       "95  [a bit of background: i'm almost certain that ...   \n",
       "96  [average day at work, not too busy, not too sl...   \n",
       "97  [let's start off with the shitty morning of me...   \n",
       "98  [yesterday evening my mother and i were walkin...   \n",
       "99  [using a throwaway because well, who knows who...   \n",
       "\n",
       "                                               scores  \n",
       "0   [([i, grew, up, in, germany, where, i, went, t...  \n",
       "1   [([during, the, most, acute, months, of, griev...  \n",
       "2   [([the, slight, peroxide, kinda, smell, ensued...  \n",
       "3   [([today, i, was, going, to, have, a, bath, af...  \n",
       "4   [([picture, this, ;, a, very, cramped, bathroo...  \n",
       "..                                                ...  \n",
       "95  [([as, i, begin, ,, as, my, friend, once, put,...  \n",
       "96  [([i, 'm, getting, ready, to, go, on, my, brea...  \n",
       "97  [([we, drove, to, wendy, 's, and, ordered, fou...  \n",
       "98  [([for, some, odd, reason, ,, i, did, n't, sit...  \n",
       "99  [([using, a, throwaway, because, well, ,, who,...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa054a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_json(\"reddit_data/reddit_rouge_100.jsonl\", orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs375] *",
   "language": "python",
   "name": "conda-env-cs375-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
